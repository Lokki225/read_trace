---
description: Intelligent implementation with real-time validation, confidence tracking, and anti-simplification enforcement
---

# Smart Implementation Workflow v2.0

## Purpose

Execute implementation with continuous validation, automatic confidence scoring, goosebumps-free development, and **MANDATORY** prevention of corner-cutting, simplification, or incomplete implementations.

---

## ï¿½ STEP -1 â€” AI Constitution Bootstrap (MANDATORY FIRST STEP)

**Before ANY implementation action, execute this bootstrap sequence:**

### Required Reading:

```
ğŸ“š BOOTSTRAP CHECKLIST:

â–¡ Read docs/AI_CONSTITUTION.md (MANDATORY)
â–¡ Scan docs/ai-memory/resolved-issues.md (Never re-solve these)
â–¡ Scan docs/ai-memory/command-playbook.md (Use known commands)
â–¡ Scan docs/ai-memory/decisions.md (Follow established patterns)
â–¡ Scan docs/ai-memory/pitfalls.md (Avoid known mistakes)
â–¡ Read AI_SESSION_MEMORY.md (Session context)
â–¡ Read IMPLEMENTATION_STATUS.json (Current work)
```

### Constitution Acknowledgment:

```
ğŸ”° AI CONSTITUTION LOADED

âœ… Execution autonomy: ENABLED
âœ… Memory discipline: ACTIVE
âœ… Cascading tasks: ENABLED
âœ… Anti-simplification: ZERO TOLERANCE
âœ… Product Layer: 100% implementation required

Proceeding with smart implementation...
```

**BLOCKING RULE**: Do not proceed to implementation until bootstrap is complete.

---

## ï¿½ğŸš¨ CRITICAL: Anti-Simplification Rules

### **ZERO TOLERANCE POLICY**

**AI Agents MUST NEVER:**

- âŒ Propose "simplified" or "minimal" versions of requirements
- âŒ Skip acceptance criteria claiming they're "optional"
- âŒ Omit edge cases or error handling
- âŒ Skip test scenarios documented in Product Layer
- âŒ Remove features to "make implementation easier"
- âŒ Suggest "implementing this later" for documented requirements
- âŒ Replace specified solutions with "simpler alternatives"
- âŒ Skip integration requirements
- âŒ Ignore performance, security, or quality requirements
- âŒ Mark stories complete without implementing ALL acceptance criteria

### **MANDATORY IMPLEMENTATION RULE**

> **Every single item in acceptance criteria, test scenarios, specifications, and risk assessments MUST be implemented EXACTLY as documented. No exceptions. No simplifications. No shortcuts.**

### **Verification Before ANY Code Change**

Before writing ANY code, AI agents MUST:

1. **Read and acknowledge** ALL Product Layer files:
   - `docs/specifications/[FEATURE].md`
   - `docs/acceptance-criteria/[FEATURE].md`
   - `docs/test-scenarios/[FEATURE].md`
   - `docs/risks/[FEATURE].md` 

2. **Create implementation checklist** from acceptance criteria
3. **Verify** every item will be implemented
4. **Confirm** no simplifications or omissions
5. **Document** the implementation approach for EACH criterion

---

## Pre-Flight Safety Check

### 1. **Product Layer Verification (MANDATORY)**

**BLOCKING CHECK**: Before ANY implementation, verify Product Layer completeness:

```
âœ… Product Layer Checklist for [FEATURE_NAME]:

ğŸ“‹ Specifications:
  â–¡ Feature specification exists at product/features/[FEATURE]/spec.md
  â–¡ Problem statement is clear and specific
  â–¡ Goals are well-defined
  â–¡ Non-goals are documented
  â–¡ User flow is complete
  â–¡ Technical constraints are listed
  â–¡ Dependencies are identified
  â–¡ Success metrics are defined

âœ… Acceptance Criteria:
  â–¡ Acceptance criteria exists at product/features/[FEATURE]/acceptance-criteria.md
  â–¡ ALL functional requirements are testable
  â–¡ ALL integration requirements are specific
  â–¡ ALL quality requirements have measurable criteria
  â–¡ ALL edge cases are documented
  â–¡ ALL error handling scenarios are defined
  â–¡ ALL performance criteria are quantified
  â–¡ ALL security requirements are specified
  â–¡ Definition of Done is complete

âœ… Test Scenarios:
  â–¡ Test scenarios exist at product/features/[FEATURE]/test-scenarios.md
  â–¡ ALL test scenarios map to acceptance criteria
  â–¡ Input/output for each scenario is defined
  â–¡ Validation rules are specific
  â–¡ Unit test requirements are listed
  â–¡ Integration test requirements are listed
  â–¡ Performance test requirements are listed
  â–¡ Security test requirements are listed
  â–¡ Test data requirements are documented

âœ… Risk Assessment:
  â–¡ Risk assessment exists at product/features/[FEATURE]/risks.md
  â–¡ Technical risks are identified
  â–¡ Product risks are identified
  â–¡ Performance risks are identified
  â–¡ Security risks are identified
  â–¡ Integration risks are identified
  â–¡ Mitigation strategies are defined
  â–¡ Monitoring metrics are specified

âœ… Implementation Tasks (MANDATORY PHASE-BASED BREAKDOWN):
  â–¡ Create implementation_tasks_phase1.md (Domain Layer)
  â–¡ Create implementation_tasks_phase2.md (Data Layer)
  â–¡ Create implementation_tasks_phase3.md (Presentation Layer)
  â–¡ Create implementation_tasks_phase4.md (Integration & Testing)
  â–¡ Each phase file contains ONLY tasks for that specific layer
  â–¡ Each phase file is independently executable and verifiable
  â–¡ Break down each acceptance criterion into granular tasks
  â–¡ Identify exact file paths for all files to create/modify
  â–¡ Add dependencies between tasks within each phase
  â–¡ Add verification commands for each phase
  â–¡ Use phase files as task tracking checklist throughout implementation
  
  ğŸš« BLOCKING RULE:
  - DO NOT create a single monolithic implementation_tasks.md
  - MUST split into multiple phase files (minimum 3-4 phases)
  - Each phase must be independently completable
  - Each phase must have clear completion criteria
  - Example structure: product/features/[FEATURE]/implementation_tasks_phase1.md

ğŸ¯ RESULT: [PASS/FAIL] - CANNOT proceed with FAIL
```

**IF ANY ITEM FAILS**:
- âŒ **STOP IMMEDIATELY**
- âŒ **DO NOT write any code**
- âŒ Report missing documentation
- âŒ Request Product Layer completion
- âŒ Wait for approval before proceeding

### 2. **Implementation Plan Validation**

- Read `docs/IMPLEMENTATION_PLAN.md` for current sequence
- Verify epic-level dependencies are satisfied
- Check story-level prerequisites are completed
- Confirm next story in sequence is ready for implementation
- Validate no circular dependency violations

### 3. **System Health Scan**

- Verify all required files exist
- Check confidence score baseline
- Validate Product Layer completeness
- Confirm Design Contracts compliance

### 4. **Platform Detection & Configuration**

- Read platformType from IMPLEMENTATION_STATUS.json
- **MANDATORY**: Set performance thresholds based on platform:
  - **Web**: <300ms interactive, <200ms API, <100ms DB
  - **Mobile**: <200ms interactive, <300ms API, <150ms DB  
  - **Desktop**: <100ms interactive, <100ms API, <50ms DB
  - **API**: <150ms interactive, <50ms API, <25ms DB
  - **CLI**: <500ms interactive, N/A API, N/A DB
- Auto-detect platform if platformType is missing
- Configure monitoring tools for platform type

### 5. **Risk Assessment**

- Analyze implementation complexity
- Identify potential failure points
- Set rollback points
- Calculate confidence impact

---

## ğŸ“‹ Acceptance Criteria Enforcement System

### **Pre-Implementation Requirements Matrix**

Before writing ANY code, create this matrix:

```
Feature: [FEATURE_NAME]
Date: [YYYY-MM-DD]
Story ID: [STORY_ID]

ACCEPTANCE CRITERIA IMPLEMENTATION MATRIX:

Functional Requirements:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Requirement           â”‚ Implementation Plan â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FR1 â”‚ [Requirement text]    â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ FR2 â”‚ [Requirement text]    â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ FR3 â”‚ [Requirement text]    â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Integration Requirements:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Integration           â”‚ Implementation Plan â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ IR1 â”‚ [Integration text]    â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ IR2 â”‚ [Integration text]    â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Quality Requirements:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Quality Req           â”‚ Implementation Plan â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ QR1 â”‚ [Quality text]        â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ QR2 â”‚ [Quality text]        â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Edge Cases:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Edge Case             â”‚ Implementation Plan â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EC1 â”‚ [Edge case text]      â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ EC2 â”‚ [Edge case text]      â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Error Handling:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Error Scenario        â”‚ Implementation Plan â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EH1 â”‚ [Error scenario]      â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ EH2 â”‚ [Error scenario]      â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Performance Criteria:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Performance Req       â”‚ Implementation Plan â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PC1 â”‚ [Performance text]    â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ PC2 â”‚ [Performance text]    â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Security Requirements:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Security Req          â”‚ Implementation Plan â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SR1 â”‚ [Security text]       â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â”‚ SR2 â”‚ [Security text]       â”‚ [How to implement] â”‚ â¬œ TODO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ TOTAL ITEMS: [COUNT]
âœ… MUST IMPLEMENT ALL: [COUNT] items
âŒ CANNOT SKIP ANY: 0 items allowed to be skipped
```

### **Continuous Verification During Implementation**

After implementing EACH requirement:

1. **Update matrix** with âœ… status
2. **Verify implementation** matches acceptance criteria EXACTLY
3. **Write test** that validates the criterion
4. **Run test** and ensure it passes
5. **Document** any deviations (there should be NONE)

### **Blocking Conditions**

**DO NOT proceed to next requirement if:**
- âŒ Current requirement not fully implemented
- âŒ Test for current requirement failing
- âŒ Implementation deviates from acceptance criteria
- âŒ Simplifications were made

---

## Implementation Loop

### **Step-by-Step Implementation Process**

For each feature:

### **Step 0: Product Layer Deep Dive (MANDATORY)**

```
ğŸ” DEEP DIVE CHECKLIST:

â–¡ Read specifications file completely
â–¡ Read acceptance criteria file completely
â–¡ Read test scenarios file completely
â–¡ Read risk assessment file completely
â–¡ Create implementation matrix from acceptance criteria
â–¡ Identify ALL requirements (count them)
â–¡ Plan implementation for EACH requirement
â–¡ Verify NO requirements are marked as "optional"
â–¡ Confirm understanding of ALL edge cases
â–¡ Confirm understanding of ALL error scenarios
â–¡ Confirm understanding of ALL performance criteria
â–¡ Confirm understanding of ALL security requirements

ğŸ¯ SIGN-OFF: I have read and understood ALL Product Layer documentation
           and will implement EVERY requirement without simplification.

Signature: [AI_AGENT_NAME]
Date: [YYYY-MM-DD]
Total Requirements: [COUNT]
Commitment: Implement ALL [COUNT] requirements
```

### **Step 0.1: Screen & UI Inventory (MANDATORY - CRITICAL)**

**ğŸš¨ CRITICAL: This step prevents incomplete feature implementations**

Before ANY coding, extract and document ALL screens/pages from product specs:

```
ğŸ“± SCREEN INVENTORY FOR [FEATURE_NAME]:

Source: product/features/[feature-name]/spec.md

Screens Section Analysis:
â–¡ Located "Screens" section in spec.md
â–¡ Read EVERY screen listed
â–¡ Counted total screens required
â–¡ No screens marked as "optional" or "future"

COMPLETE SCREEN LIST:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # â”‚ Screen Name              â”‚ File Path                   â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1 â”‚ [Screen Name]            â”‚ lib/features/.../pages/     â”‚
â”‚ 2 â”‚ [Screen Name]            â”‚ lib/features/.../pages/     â”‚
â”‚ 3 â”‚ [Screen Name]            â”‚ lib/features/.../pages/     â”‚
â”‚ 4 â”‚ [Screen Name]            â”‚ lib/features/.../pages/     â”‚
â”‚ 5 â”‚ [Screen Name]            â”‚ lib/features/.../pages/     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š SCREEN COUNT: [X] screens MUST be implemented
ğŸ¯ COMMITMENT: I will implement ALL [X] screens - NO EXCEPTIONS

Cross-Reference Check:
â–¡ Checked acceptance criteria for screen requirements
â–¡ Checked user flow for screen transitions
â–¡ Verified navigation requirements between screens
â–¡ Identified all screen dependencies

ğŸš« BLOCKING RULE:
- If spec.md lists N screens, implementation MUST have N screens
- Missing even ONE screen = INCOMPLETE FEATURE
- DO NOT mark feature as IMPLEMENTED until ALL screens exist
```

### **Step 0.1.5: Create Phase-Based Implementation Tasks (MANDATORY)**

**ğŸš¨ CRITICAL: This step prevents monolithic, unmanageable implementation files**

Before ANY coding, create separate implementation task files for each architectural phase:

```
ğŸ“‹ PHASE-BASED IMPLEMENTATION TASKS STRUCTURE:

Feature: [FEATURE_NAME]
Location: product/features/[feature-name]/

REQUIRED PHASE FILES (minimum 4 phases):

1. implementation_tasks_phase1.md - Domain Layer
   - Database schema design
   - Domain entities with validation
   - Repository interfaces (contracts)
   - Use cases with business logic
   - Custom exceptions
   - Estimated duration: 2-3 days
   - Completion criteria: All domain logic complete, no Flutter analysis errors

2. implementation_tasks_phase2.md - Data Layer
   - Data models with JSON serialization
   - Remote data sources (API integration)
   - Local data sources (caching)
   - Repository implementations
   - Error handling and retry logic
   - Estimated duration: 2-3 days
   - Completion criteria: All data access complete, proper error handling

3. implementation_tasks_phase3.md - Presentation Layer
   - BLoC/Cubit state management
   - Pages and screens
   - Widgets and components
   - Navigation setup
   - UI state handling
   - Estimated duration: 3-4 days
   - Completion criteria: All screens functional, proper state management

4. implementation_tasks_phase4.md - Integration & Testing
   - Dependency injection setup
   - Feature integration with app
   - Unit tests (domain, data, presentation)
   - Integration tests
   - Performance tests
   - Security tests
   - Estimated duration: 2-3 days
   - Completion criteria: All tests passing, coverage â‰¥80%, no lint errors

EACH PHASE FILE MUST CONTAIN:

Header Section:
- Phase number and name
- Phase overview and objectives
- Estimated duration
- Dependencies on previous phases

Task Breakdown:
- Task ID (e.g., 1.1, 1.2, 2.1)
- Task objective
- Files to create/modify
- Implementation details
- Requirements checklist
- Verification commands
- Status indicator (âœ… COMPLETE / â¬œ TODO)

Phase Completion Section:
- Completion criteria checklist
- All tasks must be marked âœ…
- Verification commands for entire phase
- Dependencies for next phase
- Next phase reference

EXAMPLE STRUCTURE FOR EACH TASK:

## Task [X.Y]: [Task Name]

**Objective**: [Clear, specific objective]

**Files to Create/Modify**:
- `path/to/file1.dart`
- `path/to/file2.dart`

**Implementation Details**:
[Detailed requirements, code structure, patterns to follow]

**Requirements**:
- Requirement 1
- Requirement 2
- Requirement 3

**Verification Command**:
\`\`\`bash
[Command to verify task completion]
\`\`\`

**Status**: âœ… COMPLETE / â¬œ TODO

---

BLOCKING RULES:

ğŸš« DO NOT create a single monolithic implementation_tasks.md
ğŸš« DO NOT combine multiple phases into one file
ğŸš« DO NOT skip any phase
ğŸš« DO NOT proceed to next phase until current phase is 100% complete
ğŸš« Each phase file must be independently executable
ğŸš« Each phase must have clear, measurable completion criteria

VERIFICATION CHECKLIST:

â–¡ Phase 1 file exists: implementation_tasks_phase1.md
â–¡ Phase 2 file exists: implementation_tasks_phase2.md
â–¡ Phase 3 file exists: implementation_tasks_phase3.md
â–¡ Phase 4 file exists: implementation_tasks_phase4.md
â–¡ Each phase file has clear header with objectives
â–¡ Each phase file has 3-6 granular tasks
â–¡ Each task has specific files to create/modify
â–¡ Each task has verification commands
â–¡ Each phase has completion criteria
â–¡ No file exceeds 15KB (split if needed)
â–¡ All acceptance criteria mapped to specific tasks
â–¡ All edge cases assigned to specific tasks
â–¡ All error scenarios assigned to specific tasks
â–¡ All performance criteria assigned to specific tasks
â–¡ All security requirements assigned to specific tasks

REFERENCE EXAMPLE:
See: product/features/parental-consent-minor-protection/
- implementation_tasks_phase1.md (Domain Layer)
- implementation_tasks_phase2.md (Data Layer)
- implementation_tasks_phase3.md (Presentation Layer)
- implementation_tasks_phase4.md (Integration & Testing)
```

### **Step 0.2: Feature Completeness Baseline (MANDATORY)**

Establish completion criteria BEFORE starting:

```
ğŸ“Š FEATURE COMPLETENESS BASELINE:

Feature: [FEATURE_NAME]
Product Spec: product/features/[feature-name]/spec.md

REQUIRED COMPONENTS INVENTORY:

1. Screens/Pages: [COUNT from spec.md "Screens" section]
   â–¡ Screen 1: [Name]
   â–¡ Screen 2: [Name]
   â–¡ Screen 3: [Name]
   ... (list ALL)

2. User Flows: [COUNT from spec.md "User Flow" section]
   â–¡ Flow 1: [Description]
   â–¡ Flow 2: [Description]
   ... (list ALL)

3. Integration Points: [COUNT from spec.md "Dependencies" section]
   â–¡ Integration 1: [System/Feature]
   â–¡ Integration 2: [System/Feature]
   ... (list ALL)

4. Functional Requirements: [COUNT from acceptance-criteria.md]
   â–¡ FR1: [Description]
   â–¡ FR2: [Description]
   ... (list ALL)

5. Non-Functional Requirements: [COUNT from acceptance-criteria.md]
   â–¡ NFR1: [Description]
   â–¡ NFR2: [Description]
   ... (list ALL)

ğŸ¯ TOTAL COMPLETION ITEMS: [SUM of all counts]
ğŸ“ˆ COMPLETION FORMULA: (Implemented Items / Total Items) Ã— 100%
ğŸš« MINIMUM FOR "IMPLEMENTED" STATUS: 100% (ALL items)

âš ï¸ WARNING: Feature marked IMPLEMENTED with <100% = VIOLATION
```

### **Step 0.3: Phase-Based Task Execution Protocol (MANDATORY)**

**How to use phase-based implementation task files:**

```
ğŸ”„ PHASE EXECUTION WORKFLOW:

BEFORE STARTING PHASE 1:
â–¡ All 4 phase files created (phase1.md through phase4.md)
â–¡ Each phase file has clear completion criteria
â–¡ Each task has specific files to create/modify
â–¡ All acceptance criteria mapped to tasks
â–¡ Estimated timeline for all phases established

DURING EACH PHASE:
â–¡ Read entire phase file before starting any tasks
â–¡ Complete tasks in order (1.1, 1.2, 1.3, etc.)
â–¡ For each task:
  - Read objective and requirements
  - Create/modify specified files
  - Run verification command
  - Mark task status as âœ… COMPLETE
  - DO NOT proceed to next task until current is complete
â–¡ After all tasks in phase complete:
  - Run phase-level verification commands
  - Check all completion criteria
  - Verify no lint/analysis errors
  - Document any deviations
  - Mark entire phase as âœ… COMPLETE

BLOCKING RULES FOR PHASES:
ğŸš« Cannot start Phase 2 until Phase 1 is 100% complete
ğŸš« Cannot start Phase 3 until Phase 2 is 100% complete
ğŸš« Cannot start Phase 4 until Phase 3 is 100% complete
ğŸš« Cannot mark feature IMPLEMENTED until Phase 4 is 100% complete

PHASE INTERDEPENDENCIES:
Phase 1 (Domain) â†’ Foundation for all other phases
Phase 2 (Data) â†’ Depends on Phase 1 entities and repositories
Phase 3 (Presentation) â†’ Depends on Phase 2 repositories
Phase 4 (Integration) â†’ Depends on all previous phases

TASK TRACKING:
- Update task status in phase file as you complete each task
- Mark âœ… COMPLETE only when:
  - Code written and committed
  - Verification command passes
  - No new lint/analysis errors introduced
  - All requirements from task met
- If task fails verification:
  - DO NOT mark as complete
  - Debug and fix issues
  - Re-run verification
  - Only mark complete when passing

PHASE COMPLETION SIGN-OFF:
When phase is 100% complete:
- All tasks marked âœ… COMPLETE
- All completion criteria checked
- Phase-level verification commands pass
- Ready for next phase
- Update IMPLEMENTATION_STATUS.json with phase progress
```

### **Step 1: Dependency Check**
- Verify IMPLEMENTATION_PLAN.md allows this story
- Check all prerequisite stories are COMPLETE
- Validate no blocking dependencies exist
- **NEW**: Verify all 4 phase files exist and are complete

### **Step 2: Analyze**
- Read all context files
- **RE-READ** Product Layer files (specifications, acceptance criteria, test scenarios, risks)
- Create detailed notes on EVERY requirement

### **Step 3: Plan**
- Create implementation strategy
- **Map strategy to EVERY acceptance criterion**
- Identify files to create/modify for EACH requirement
- Plan test implementation for EACH requirement
- **NO SIMPLIFICATIONS ALLOWED**

### **Step 4: Domain Layer Implementation**

**For EACH acceptance criterion requiring domain logic:**

```
âœ… Domain Implementation Checklist:

â–¡ Entity created with ALL required properties
â–¡ Entity includes ALL validation rules from acceptance criteria
â–¡ Entity handles ALL edge cases documented
â–¡ Repository contract defined with ALL required methods
â–¡ Use case created for EACH functional requirement
â–¡ Use case implements ALL business logic exactly as specified
â–¡ Use case handles ALL error scenarios from acceptance criteria
â–¡ Use case validates ALL inputs as per quality requirements
â–¡ Use case returns proper Either<Failure, Success> for ALL cases
â–¡ ALL domain tests written and passing

ğŸš« BLOCKERS:
- Missing ANY property from specifications
- Skipping ANY validation rule
- Ignoring ANY edge case
- Simplifying ANY business logic
```

### **Step 5: Data Layer Implementation**

**For EACH data requirement:**

```
âœ… Data Layer Implementation Checklist:

â–¡ Model created with ALL fields from entity
â–¡ Model includes proper JSON serialization
â–¡ Model handles ALL data transformation edge cases
â–¡ Remote data source implements ALL API calls from integration requirements
â–¡ Data source handles ALL network error scenarios
â–¡ Data source implements ALL retry logic from quality requirements
â–¡ Repository implementation delegates to data sources correctly
â–¡ Repository handles ALL error mapping
â–¡ Repository implements ALL caching requirements
â–¡ ALL data layer tests written and passing

ğŸš« BLOCKERS:
- Missing ANY field from entity
- Skipping ANY API endpoint
- Ignoring ANY error scenario
- Removing ANY caching requirement
```

### **Step 6: Presentation Layer Implementation**

**For EACH UI requirement:**

```
âœ… Presentation Layer Implementation Checklist:

â–¡ BLoC events defined for ALL user actions
â–¡ BLoC states defined for ALL UI states from specifications
â–¡ BLoC implements ALL business logic delegation
â–¡ BLoC handles ALL error states from acceptance criteria
â–¡ BLoC implements ALL loading states
â–¡ Page created with ALL UI elements from specifications
â–¡ Page handles ALL user interactions
â–¡ Page displays ALL error messages as specified
â–¡ Widgets created for ALL reusable components
â–¡ Widgets implement ALL accessibility requirements
â–¡ ALL presentation tests written and passing

ğŸš« BLOCKERS:
- Missing ANY user action handler
- Skipping ANY UI state
- Ignoring ANY error message
- Removing ANY accessibility feature
```

### **Step 7: Navigation Implementation**

```
âœ… Navigation Implementation Checklist:

â–¡ Routes defined for ALL pages
â–¡ Navigation flow matches user flow in specifications
â–¡ Deep links implemented as per requirements
â–¡ Auth guards applied to ALL protected routes
â–¡ Back navigation works for ALL screens
â–¡ Navigation state persists across app restarts
â–¡ Tab/drawer integration complete
â–¡ ALL navigation tests written and passing

ğŸš« BLOCKERS:
- Missing ANY route
- Skipping ANY auth guard
- Ignoring ANY deep link requirement
```

### **Step 8: Database Implementation**

```
âœ… Database Implementation Checklist:

â–¡ Schema file updated with ALL required tables
â–¡ ALL entity tables created with correct columns
â–¡ ALL relationships defined with foreign keys
â–¡ ALL indexes created for performance requirements
â–¡ ALL constraints added for data integrity
â–¡ ALL RLS policies implemented for security requirements
â–¡ ALL triggers created for data consistency
â–¡ Sample test data added
â–¡ Database migration script created
â–¡ ALL database tests written and passing

ğŸš« BLOCKERS:
- Missing ANY table
- Skipping ANY index for performance
- Ignoring ANY RLS policy for security
- Missing ANY constraint for integrity
```

### **Step 9: Test Implementation (MANDATORY)**

**For EVERY test scenario in test-scenarios file:**

```
âœ… Test Implementation Checklist:

Test Scenario: [TS-XXX]
Description: [Test scenario description]

â–¡ Test scenario ID matches acceptance criteria ID
â–¡ Test written for exact input specified
â–¡ Test validates exact expected output
â–¡ Test checks ALL validation rules
â–¡ Test handles ALL edge cases
â–¡ Test verifies ALL error conditions
â–¡ Test meets performance criteria
â–¡ Test validates security requirements
â–¡ Test uses proper test data
â–¡ Test includes cleanup procedures

Unit Tests:
â–¡ Test 1: [Description] - [Status: âœ…/âŒ]
â–¡ Test 2: [Description] - [Status: âœ…/âŒ]
â–¡ Test 3: [Description] - [Status: âœ…/âŒ]

Integration Tests:
â–¡ Test 1: [Description] - [Status: âœ…/âŒ]
â–¡ Test 2: [Description] - [Status: âœ…/âŒ]

Performance Tests:
â–¡ Test 1: [Description] - [Status: âœ…/âŒ]

Security Tests:
â–¡ Test 1: [Description] - [Status: âœ…/âŒ]

ğŸ¯ COVERAGE: [XX]% (Minimum: 80% for ALL new code)
```

**BLOCKING CONDITION:**
- âŒ **ANY test scenario from Product Layer not implemented = FAIL**
- âŒ **ANY test failing = FAIL**
- âŒ **Coverage below 80% = FAIL**

### **Step 10: Quality Validation**

```
âœ… Quality Validation Checklist:

Code Quality:
â–¡ Flutter analyze: No issues found!
â–¡ ALL lint errors fixed
â–¡ ALL warnings addressed
â–¡ Code follows design patterns
â–¡ No code duplication
â–¡ Proper error handling everywhere
â–¡ Logging implemented correctly

Performance:
â–¡ Meets platform-specific thresholds
â–¡ No memory leaks detected
â–¡ Smooth animations (60fps)
â–¡ Efficient database queries
â–¡ Proper lazy loading implemented

Security:
â–¡ ALL security requirements from acceptance criteria implemented
â–¡ Input validation on ALL inputs
â–¡ Proper authentication checks
â–¡ Data encryption where required
â–¡ No sensitive data in logs

Accessibility:
â–¡ Screen reader support
â–¡ Proper contrast ratios
â–¡ Keyboard navigation
â–¡ Focus management

Documentation:
â–¡ Code comments for complex logic
â–¡ API documentation updated
â–¡ README updated if needed
â–¡ CHANGELOG entry added
```

### **Step 11: Comprehensive Feature Verification**

**MANDATORY VERIFICATION BEFORE UPDATING IMPLEMENTATION_STATUS.json**

#### 11.1 **Story Requirements Verification**

```
âœ… Story Verification:

â–¡ Read story file: docs/stories/[STORY_ID].md
â–¡ ALL acceptance criteria implemented (no exceptions)
â–¡ ALL tasks/subtasks completed
â–¡ ALL integration requirements met
â–¡ ALL edge cases handled
â–¡ ALL error scenarios implemented
â–¡ ALL performance criteria met
â–¡ ALL security requirements satisfied

ğŸ” VERIFICATION METHOD:
For EACH acceptance criterion:
1. Find the code that implements it
2. Find the test that validates it
3. Confirm test passes
4. Confirm no simplifications were made

ğŸ“Š SCORE: [X]/[TOTAL] criteria implemented
ğŸ¯ REQUIRED: [TOTAL]/[TOTAL] (100%)
```

#### 11.2 **Technical Implementation Verification**

```
âœ… Technical Verification:

Domain Layer:
â–¡ ALL entities exist and are complete
â–¡ ALL repositories defined
â–¡ ALL use cases implemented
â–¡ NO business logic in other layers

Data Layer:
â–¡ ALL models implement ALL entity properties
â–¡ ALL datasources implement ALL API endpoints
â–¡ ALL repositories implement ALL contracts
â–¡ ALL error handling implemented

Presentation Layer:
â–¡ ALL BLoCs created and functional
â–¡ ALL pages created and accessible
â–¡ ALL widgets implemented
â–¡ ALL UI states handled

Database:
â–¡ Schema deployed with ALL tables
â–¡ ALL indexes created
â–¡ ALL RLS policies active
â–¡ ALL triggers functional

Navigation:
â–¡ Feature accessible from app
â–¡ ALL routes working
â–¡ Auth flow correct
â–¡ Deep links functional
```

#### 11.3 **Quality Assurance Verification**

```
âœ… Quality Verification:

â–¡ Flutter analyze: No issues found!
â–¡ ALL tests passing (0 failures)
â–¡ Test coverage â‰¥ 80%
â–¡ Performance meets platform thresholds
â–¡ No memory leaks
â–¡ No security vulnerabilities
â–¡ Accessibility requirements met
```

#### 11.4 **Integration Verification**

```
âœ… Integration Verification:

â–¡ Authentication integration working
â–¡ State management connected
â–¡ Design system components used
â–¡ Observability/logging implemented
â–¡ Dependency injection configured
â–¡ Feature works with existing features
â–¡ No breaking changes to other features
```

#### 11.5 **User Experience Verification**

```
âœ… UX Verification:

â–¡ Feature accessible in app
â–¡ UI follows design system
â–¡ Error handling provides clear feedback
â–¡ Loading states implemented
â–¡ Success confirmations shown
â–¡ Performance feels smooth
â–¡ Works offline if required
â–¡ Responsive on all screen sizes
```

### **Step 12: Final Acceptance Criteria Audit**

**BEFORE marking as complete, perform this audit:**

```
ğŸ” FINAL AUDIT: [FEATURE_NAME]

Acceptance Criteria Audit:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Criterion ID â”‚ Implemented? â”‚ Tested? â”‚ Verified? â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FR1          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ FR2          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ FR3          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ IR1          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ IR2          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ QR1          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ QR2          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ EC1          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ EC2          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ EH1          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ EH2          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ PC1          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ PC2          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ SR1          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â”‚ SR2          â”‚ âœ…           â”‚ âœ…      â”‚ âœ…        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š COMPLETION SCORE:
- Total Criteria: [COUNT]
- Implemented: [COUNT]
- Tested: [COUNT]
- Verified: [COUNT]

ğŸ¯ REQUIREMENT: ALL must be 100%

âŒ IF ANY CRITERION IS NOT âœ…âœ…âœ…:
   - DO NOT mark as complete
   - DO NOT update IMPLEMENTATION_STATUS.json
   - FIX the missing implementation
   - RE-RUN this audit
```

### **Step 12.1: Screen Completeness Verification (MANDATORY)**

**ğŸš¨ CRITICAL: Cross-check ALL screens from product spec**

```
ğŸ“± SCREEN COMPLETENESS AUDIT:

Feature: [FEATURE_NAME]
Source: product/features/[feature-name]/spec.md

Step 1: Extract Required Screens from Spec
â–¡ Opened spec.md file
â–¡ Located "Screens" section (usually around line 40-50)
â–¡ Listed EVERY screen mentioned
â–¡ Counted total screens: [N]

Step 2: Verify Implementation
â–¡ Checked lib/features/[feature]/presentation/pages/ directory
â–¡ Counted implemented screens: [M]
â–¡ Compared: M must equal N

Screen-by-Screen Verification:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # â”‚ Screen Name (from spec)  â”‚ File Exists? â”‚ Functional? â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1 â”‚ [Screen Name]            â”‚ âœ…/âŒ        â”‚ âœ…/âŒ       â”‚
â”‚ 2 â”‚ [Screen Name]            â”‚ âœ…/âŒ        â”‚ âœ…/âŒ       â”‚
â”‚ 3 â”‚ [Screen Name]            â”‚ âœ…/âŒ        â”‚ âœ…/âŒ       â”‚
â”‚ 4 â”‚ [Screen Name]            â”‚ âœ…/âŒ        â”‚ âœ…/âŒ       â”‚
â”‚ 5 â”‚ [Screen Name]            â”‚ âœ…/âŒ        â”‚ âœ…/âŒ       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š SCREEN COMPLETION RATE: [M]/[N] = [X]%

ğŸ¯ REQUIREMENT: 100% (ALL screens must exist and be functional)

âŒ BLOCKING CONDITIONS:
- If M < N: Feature is INCOMPLETE
- If any screen marked âŒ: Feature is INCOMPLETE
- DO NOT mark feature as IMPLEMENTED
- DO NOT update FEATURE_STATUS.json to IMPLEMENTED
- CREATE missing screens before proceeding

âœ… ONLY IF M = N AND ALL âœ…:
- Feature screens are complete
- May proceed to mark as IMPLEMENTED
```

### **Step 12.2: Integration Completeness Verification (MANDATORY)**

**Verify ALL integration points from product spec**

```
ğŸ”— INTEGRATION COMPLETENESS AUDIT:

Feature: [FEATURE_NAME]
Source: product/features/[feature-name]/spec.md (Dependencies section)

Required Integrations (from spec.md):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # â”‚ Integration Point      â”‚ Implemented? â”‚ Tested?   â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1 â”‚ [Integration name]     â”‚ âœ…/âŒ        â”‚ âœ…/âŒ     â”‚
â”‚ 2 â”‚ [Integration name]     â”‚ âœ…/âŒ        â”‚ âœ…/âŒ     â”‚
â”‚ 3 â”‚ [Integration name]     â”‚ âœ…/âŒ        â”‚ âœ…/âŒ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Integration Details:
â–¡ Authentication integration working
â–¡ State management connected
â–¡ Navigation routes configured
â–¡ Database schema deployed
â–¡ API endpoints accessible
â–¡ Feature flags configured
â–¡ Observability/logging active
â–¡ Dependency injection setup

ğŸ“Š INTEGRATION COMPLETION: [X]/[TOTAL] = [Y]%

ğŸ¯ REQUIREMENT: 100% (ALL integrations must work)

âŒ IF ANY INTEGRATION MISSING:
- Feature is INCOMPLETE
- DO NOT mark as IMPLEMENTED
- COMPLETE missing integrations first
```

### **Step 12.3: Feature Completeness Percentage Calculation (MANDATORY)**

**Calculate exact completion percentage before marking IMPLEMENTED**

```
ğŸ“Š FEATURE COMPLETENESS CALCULATION:

Feature: [FEATURE_NAME]
Date: [YYYY-MM-DD]

Component Inventory:
1. Screens/Pages:
   - Required (from spec.md): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

2. User Flows:
   - Required (from spec.md): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

3. Functional Requirements:
   - Required (from acceptance-criteria.md): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

4. Integration Points:
   - Required (from spec.md Dependencies): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

5. Tests:
   - Required (from test-scenarios.md): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

6. Edge Cases:
   - Required (from acceptance-criteria.md): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

7. Error Handling:
   - Required (from acceptance-criteria.md): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

8. Performance Criteria:
   - Required (from acceptance-criteria.md): [N]
   - Validated: [M]
   - Completion: [M/N Ã— 100]%

9. Security Requirements:
   - Required (from acceptance-criteria.md): [N]
   - Implemented: [M]
   - Completion: [M/N Ã— 100]%

ğŸ“ˆ OVERALL FEATURE COMPLETION:
Formula: Average of all component completions
Result: [PERCENTAGE]%

ğŸ¯ IMPLEMENTATION STATUS RULES:
- 100%: Mark as IMPLEMENTED âœ…
- 90-99%: INCOMPLETE - Missing critical elements âŒ
- 80-89%: INCOMPLETE - Significant gaps âŒ
- <80%: INCOMPLETE - Major work remaining âŒ

ğŸš¨ CRITICAL RULE:
ONLY mark feature as IMPLEMENTED if completion = 100%
ANY percentage < 100% = Feature is INCOMPLETE

âŒ IF COMPLETION < 100%:
1. DO NOT update FEATURE_STATUS.json to IMPLEMENTED
2. DO NOT update IMPLEMENTATION_STATUS.json with "completed"
3. IDENTIFY missing components from calculation above
4. CREATE/IMPLEMENT missing components
5. RE-RUN this calculation
6. ONLY proceed when 100% achieved
```

### **Step 13: Final Pre-Commit Verification (BLOCKING)**

**ğŸš¨ MANDATORY: All checks must pass before marking IMPLEMENTED**

```
âœ… FINAL PRE-COMMIT CHECKLIST:

Product Spec Compliance:
â–¡ ALL screens from spec.md implemented (100%)
â–¡ ALL user flows from spec.md working (100%)
â–¡ ALL dependencies from spec.md integrated (100%)
â–¡ ALL success metrics from spec.md measurable

Acceptance Criteria Compliance:
â–¡ ALL functional requirements implemented (100%)
â–¡ ALL integration requirements working (100%)
â–¡ ALL quality requirements met (100%)
â–¡ ALL edge cases handled (100%)
â–¡ ALL error scenarios implemented (100%)
â–¡ ALL performance criteria validated (100%)
â–¡ ALL security requirements satisfied (100%)

Implementation Completeness:
â–¡ Feature completeness calculation = 100%
â–¡ Screen completeness audit = 100%
â–¡ Integration completeness audit = 100%
â–¡ NO TODOs remaining in feature code
â–¡ NO placeholder implementations
â–¡ NO "implement later" comments

Code Quality:
â–¡ Confidence score â‰¥ 75
â–¡ ALL tests passing (0 failures)
â–¡ Test coverage â‰¥ 80%
â–¡ Flutter analyze: No issues found!
â–¡ No lint errors
â–¡ No lint warnings

Validation:
â–¡ Performance validated against thresholds
â–¡ Security validated against requirements
â–¡ User experience validated (feature is usable)
â–¡ Documentation updated

ğŸ¯ PASS CRITERIA: ALL boxes must be checked (âœ…)

âŒ IF ANY BOX UNCHECKED:
- Feature is INCOMPLETE
- DO NOT proceed to commit
- DO NOT update FEATURE_STATUS.json
- DO NOT update IMPLEMENTATION_STATUS.json
- FIX missing items
- RE-RUN this checklist

âœ… ONLY IF ALL BOXES CHECKED:
Proceed to Step 14: Commit and Status Update
```

### **Step 14: Commit and Status Update (Only if Step 13 passed)**

```
âœ… Commit Checklist:

â–¡ Step 13 Final Pre-Commit Verification: PASSED âœ…
â–¡ Feature completeness: 100% âœ…
â–¡ All screens implemented âœ…
â–¡ All integrations working âœ…
â–¡ Confidence score â‰¥ 75 âœ…
â–¡ ALL acceptance criteria implemented âœ…
â–¡ ALL tests passing âœ…
â–¡ Flutter analyze clean âœ…
â–¡ Documentation updated âœ…

Status Updates:
â–¡ Update product/FEATURE_STATUS.json: state = "IMPLEMENTED"
â–¡ Update IMPLEMENTATION_STATUS.json with completion details
â–¡ Add evidence to confidenceMetrics.evidence array
â–¡ Document feature completion percentage (must be 100%)

Commit Message Template:
feat([FEATURE_ID]): Complete [Feature Name] implementation

Implemented:
- [All N screens from spec.md]
- [All M functional requirements]
- [All K integrations]
- [Criterion 1]
- [Criterion 2]
- [Criterion 3]

Completion: 100%
Screens: [N]/[N] (100%)
Tests: [X] passing
Coverage: [XX]%
Confidence: [XX]

Closes #[FEATURE_ID]
```

---

## ğŸš« BLOCKING CONDITIONS - NEVER PROCEED IF

### **Product Layer Incomplete**
- âŒ Specifications missing or incomplete
- âŒ Acceptance criteria not fully defined
- âŒ Test scenarios not documented
- âŒ Risk assessment not performed

### **Requirements Not Met**
- âŒ ANY acceptance criterion not implemented
- âŒ ANY test scenario not written
- âŒ ANY edge case not handled
- âŒ ANY error scenario not implemented
- âŒ ANY performance criterion not met
- âŒ ANY security requirement not satisfied

### **Quality Issues**
- âŒ Flutter analyze shows errors
- âŒ ANY test failing
- âŒ Test coverage below 80%
- âŒ Performance below platform thresholds
- âŒ Lint errors exist in ANY file

### **Integration Issues**
- âŒ Feature not accessible from app
- âŒ Navigation not working
- âŒ Authentication broken
- âŒ State management not connected
- âŒ Database schema not deployed

### **Simplification Detected**
- âŒ Any requirement marked as "we can skip this"
- âŒ Any "simple version" proposed
- âŒ Any "implement later" suggestions
- âŒ Any edge cases ignored
- âŒ Any error handling omitted

---

## Code Quality Standards (MANDATORY)

### ğŸš« **CRITICAL RULE: Zero Lint Errors Policy**

**NEVER move to create or edit another file if the current file has lint errors.**

#### Implementation Process:
1. **Create/Edit File** - Make changes to current file
2. **Run Flutter Analyze** - `flutter analyze` on current file
3. **Fix ALL Lint Errors** - Zero tolerance for lint issues
4. **Validate Clean State** - `flutter analyze` shows "No issues found!"
5. **Proceed to Next File** - Only after current file is clean

#### ğŸ”´ **BLOCKING CONDITIONS**:
- âŒ **DO NOT** create new files if current file has lint errors
- âŒ **DO NOT** edit other files if current file has lint errors  
- âŒ **DO NOT** proceed to next implementation step if lint errors exist
- âŒ **DO NOT** commit code if any files have lint errors

#### âœ… **ALLOWED ACTIONS**:
- âœ… Fix lint errors in current file
- âœ… Run tests on current file
- âœ… Validate current file functionality
- âœ… Proceed to next file ONLY when current file is clean

### Flutter Analysis Compliance

- **use_super_parameters**: Use `super.parameter` syntax instead of explicit parameter passing
- **prefer_const_constructors**: Use `const` constructors whenever possible for performance
- **avoid_print**: Never use `print()` in production code - use proper logging instead
- **unused_import**: Remove all unused imports
- **dead_code**: Remove unreachable code
- **invalid_null_aware_operator**: Fix unnecessary null-aware operators
- **unnecessary_non_null_assertion**: Remove unnecessary non-null assertions

### Implementation Rules

1. **Constructor Optimization**

   ```dart
   // âŒ Bad
   class MyFailure extends Failure {
     const MyFailure(String message) : super(message);
   }
   
   // âœ… Good  
   class MyFailure extends Failure {
     const MyFailure(super.message);
   }
   ```

2. **Const Constructor Usage**

   ```dart
   // âŒ Bad
   return Left(ValidationFailure('Error message'));
   
   // âœ… Good
   return const Left(ValidationFailure('Error message'));
   ```

3. **Logging Standards**

   ```dart
   // âŒ Bad
   print('Debug message');
   
   // âœ… Good
   AppLogger.debug('Debug message', 'MyClass');
   // For standalone scripts, use simple print with context
   _logInfo('Debug message');
   ```

### Automated Validation

After each implementation:

1. Run `flutter analyze` - must show "No issues found!"
2. Run `flutter test` - all tests must pass
3. Check confidence score - must not drop below 75
4. Verify no new lint warnings introduced

---

## Best Practices & Anti-Patterns

### âœ… **DO: Best Practices**

1. **Implement First, Optimize Later**
   - Implement ALL requirements completely
   - THEN optimize if needed
   - NEVER skip requirements for "performance"

2. **Follow Acceptance Criteria Exactly**
   - Read each criterion word-by-word
   - Implement exactly as written
   - Ask for clarification if ambiguous
   - NEVER interpret as "optional"

3. **Test-Driven Development**
   - Write test for acceptance criterion
   - Implement to make test pass
   - Verify test passes
   - Move to next criterion

4. **Incremental Commits**
   - Commit after each complete acceptance criterion
   - Include test in commit
   - Document what criterion was implemented
   - Never commit incomplete implementations

5. **Error Handling Everywhere**
   - EVERY API call has error handling
   - EVERY user input is validated
   - EVERY edge case is handled
   - EVERY error has user-friendly message

6. **Performance by Design**
   - Use proper indexes on database
   - Implement lazy loading where appropriate
   - Cache expensive operations
   - Monitor and measure performance

7. **Security First**
   - Validate ALL inputs
   - Sanitize ALL outputs
   - Use proper authentication
   - Implement authorization checks
   - Encrypt sensitive data

### âŒ **DON'T: Anti-Patterns to Avoid**

1. **NEVER Simplify Requirements**
   - âŒ "This is too complex, let's simplify"
   - âŒ "We can skip this edge case"
   - âŒ "This error handling is overkill"
   - âœ… "I will implement exactly as specified"

2. **NEVER Skip Testing**
   - âŒ "I'll write tests later"
   - âŒ "This is too simple to test"
   - âŒ "Manual testing is enough"
   - âœ… "Every requirement has automated tests"

3. **NEVER Ignore Edge Cases**
   - âŒ "Users won't do that"
   - âŒ "This edge case is unlikely"
   - âŒ "We can handle this later"
   - âœ… "Every documented edge case is handled"

4. **NEVER Cut Corners on Security**
   - âŒ "We'll add security later"
   - âŒ "This is internal, security doesn't matter"
   - âŒ "Input validation is too slow"
   - âœ… "Security is implemented from day one"

5. **NEVER Assume Requirements**
   - âŒ "I think users want this instead"
   - âŒ "This is better than what's documented"
   - âŒ "The spec is wrong, I'll fix it"
   - âœ… "I implement exactly what's documented"

6. **NEVER Hide Issues**
   - âŒ "I'll fix this later"
   - âŒ "This test failure doesn't matter"
   - âŒ "Let's ignore this warning"
   - âœ… "I report and fix all issues immediately"

7. **NEVER Mark Incomplete as Complete**
   - âŒ "90% is good enough"
   - âŒ "We can finish the rest later"
   - âŒ "Close enough to acceptance criteria"
   - âœ… "100% of acceptance criteria or it's not done"

---

## Automatic Safety Nets

### **Confidence Drop Detection**
- Auto-pause if score drops >20 points
- Investigate cause of drop
- Fix issues before continuing
- Never proceed with low confidence

### **Rollback Triggers**
- Auto-revert on critical failures
- Restore last known good state
- Document what went wrong
- Plan fix before retrying

### **Progress Validation**
- Ensure real progress, not documentation churn
- Verify code changes match documentation
- Check tests actually validate requirements
- Confirm features are usable

### **Acceptance Criteria Compliance**
- Auto-check implementation against criteria
- Flag any missing implementations
- Block completion if criteria not met
- Require explicit acknowledgment

---
## ğŸš¨ ESCALATION PROCEDURES (CONTINUATION)

### **When to Escalate**

If **ANY** of the following conditions occur, the AI agent **MUST STOP immediately** and escalate to the human owner (you):

1. **Ambiguous Requirements**

   * Acceptance criteria unclear or contradictory
   * Missing inputs, outputs, or constraints
   * Conflicting specs between Product Layer documents
     ğŸ‘‰ **Action:**
   * Pause implementation
   * List ambiguities explicitly
   * Ask for clarification
   * Do **NOT** infer or "fix" the spec

2. **Specification Conflicts**

   * PRD contradicts Acceptance Criteria
   * Test scenarios conflict with specifications
   * Risk mitigation contradicts performance/security rules
     ğŸ‘‰ **Action:**
   * Stop all coding
   * Report conflict with file references
   * Wait for authoritative resolution

3. **Unimplementable Requirement**

   * Requirement is technically impossible as written
   * Platform limitations prevent compliance
   * Third-party dependency blocks compliance
     ğŸ‘‰ **Action:**
   * Provide a technical explanation
   * Propose **ONLY** spec-compliant alternatives
   * Await explicit approval before proceeding

4. **Confidence Score Collapse**

   * Confidence drops below **60**
   * Confidence fluctuates unpredictably
   * Confidence degradation cause unclear
     ğŸ‘‰ **Action:**
   * Freeze progress
   * Diagnose root cause
   * Fix before proceeding

5. **Security or Safety Uncertainty**

   * Any doubt regarding data protection
   * Any uncertainty involving minors
   * Any AI safety ambiguity
     ğŸ‘‰ **Action:**
   * Default to **maximum safety**
   * Escalate immediately
   * Do not experiment

---

## ğŸ§  AI AGENT BEHAVIORAL CONTRACT

### **Mandatory Agent Mindset**

The AI agent operating under this workflow is:

* âŒ **NOT** a junior developer
* âŒ **NOT** a fast prototype generator
* âŒ **NOT** a "good enough" implementer

âœ… The agent **IS**:

* A **senior engineer**
* A **compliance-aware architect**
* A **pedagogical explainer**
* A **discipline enforcer**
* A **guardian of long-term maintainability**

---

## ğŸ“ Pedagogical Obligation (VERY IMPORTANT)

After **EVERY story**, the AI agent **MUST** provide an explanation section.

### **Mandatory Post-Story Explanation**

```
ğŸ“˜ STORY IMPLEMENTATION EXPLANATION

Story ID: [STORY_ID]
Epic: [EPIC_NAME]

1. Purpose of This Story
   - Why this story exists
   - What problem it solves in the product

2. What Was Implemented
   - Domain logic
   - Data flow
   - UI behavior
   - Side effects

3. File-by-File Breakdown
   - File name â†’ Responsibility
   - Why this file exists
   - How it collaborates with others

4. Architectural Alignment
   - Clean Architecture layer mapping
   - Dependency direction validation
   - Why this design was chosen

5. Acceptance Criteria Mapping
   - AC â†’ Code â†’ Test mapping
   - Proof that nothing was skipped

6. Common Mistakes Avoided
   - What shortcuts were NOT taken
   - What anti-patterns were explicitly avoided

7. Future Impact
   - How this affects future features
   - What would break if done incorrectly

8. Confidence Assessment
   - Current confidence score
   - What improved it
   - What could reduce it in future
```

ğŸ‘‰ **This explanation is NOT OPTIONAL.**
It is part of the Definition of Done.

---

## ğŸ“Š Confidence Scoring Model (Formalized)

### Confidence Score Factors

| Dimension                      | Weight |
| ------------------------------ | ------ |
| Acceptance Criteria Coverage   | 30%    |
| Test Coverage & Quality        | 25%    |
| Architectural Integrity        | 15%    |
| Error & Edge Case Handling     | 15%    |
| Performance Compliance         | 10%    |
| Code Readability & Cleanliness | 5%     |

### Confidence Interpretation

* **90â€“100** â†’ Exceptional, production-grade
* **75â€“89** â†’ Acceptable, safe to proceed
* **60â€“74** â†’ Warning, proceed with caution
* **< 60** â†’ ğŸš« STOP IMMEDIATELY

---

## ğŸ§­ Workflow Position Awareness

At all times, the AI agent must be able to answer:

* Which **Epic** am I in?
* Which **Story** am I implementing?
* Which **Acceptance Criterion** am I working on?
* Which **Layer** am I touching?
* Which **Test** validates this?

If the agent **cannot answer instantly**, it must stop.

---

## ğŸ§© Clean Architecture Enforcement (Flutter)

The workflow **MUST** respect Flutter Clean Architecture:

```
presentation/
  â”œâ”€â”€ pages/
  â”œâ”€â”€ widgets/
  â”œâ”€â”€ blocs/
domain/
  â”œâ”€â”€ entities/
  â”œâ”€â”€ usecases/
  â”œâ”€â”€ repositories/
data/
  â”œâ”€â”€ models/
  â”œâ”€â”€ datasources/
  â”œâ”€â”€ repositories/
```

ğŸš« **Forbidden:**

* Business logic in UI
* API calls in BLoC
* Data models used in UI
* UI imports in domain layer

---

## ğŸ§ª Test Philosophy (Non-Negotiable)

* Tests are **evidence**, not decoration
* A feature without tests **does not exist**
* Passing tests are required, but **insufficient**
* Tests must **prove compliance**, not coverage vanity

---

## ğŸ§  Final Rule (The "Professor Rule")

> If the implementation cannot be explained clearly to a student **after it is written**, it is considered **incorrect**, even if it works.

Readable > clever
Explicit > implicit
Correct > fast

---

---

## ğŸ“ Phase-Based Implementation Task Template

**Use this template to create each phase file:**

```markdown
# [FEATURE_NAME] Implementation Tasks - Phase [X]: [PHASE_NAME]

## Phase [X] Overview
This phase [brief description of what this phase accomplishes]. Estimated duration: [X-Y] days.

---

## Task [X].1: [Task Name]

**Objective**: [Clear, specific objective]

**Files to Create/Modify**:
- `path/to/file1.dart`
- `path/to/file2.dart`

**Implementation Details**:
[Detailed requirements, code structure, patterns to follow]

**Requirements**:
- Requirement 1
- Requirement 2
- Requirement 3

**Verification Command**:
\`\`\`bash
[Command to verify task completion]
\`\`\`

**Status**: â¬œ TODO

---

## Task [X].2: [Task Name]

[Repeat structure above for each task]

---

## Phase [X] Completion Criteria

- [ ] All tasks completed and marked âœ… COMPLETE
- [ ] All files created with proper structure
- [ ] No Flutter analysis errors
- [ ] All verification commands pass
- [ ] Code follows project conventions
- [ ] All requirements from acceptance criteria met

**Estimated Completion Time**: [X-Y] days
**Dependencies**: [List previous phases or external dependencies]
**Next Phase**: Phase [X+1] - [Phase Name]
```

**CRITICAL REMINDERS:**

- âœ… Create 4 separate phase files (minimum)
- âœ… Each phase file focuses on ONE architectural layer
- âœ… Each task has specific files to create/modify
- âœ… Each task has verification commands
- âœ… All acceptance criteria mapped to specific tasks
- âœ… Phase files are independently executable
- âœ… No file exceeds 15KB (split if needed)
- âŒ DO NOT create monolithic implementation_tasks.md
- âŒ DO NOT combine phases into single file
- âŒ DO NOT skip verification commands
- âŒ DO NOT proceed to next phase until current is 100% complete

---

## âœ… FINAL STATUS

This workflow is now:

* âœ” Compatible with **BMAD**
* âœ” Compatible with **Flutter Clean Architecture**
* âœ” Safe for **AI agents**
* âœ” Suitable for **long-lived products**
* âœ” Pedagogical by design
* âœ” Resistant to shortcutting
* âœ” Ready for real development
* âœ” **Enforces phase-based task breakdown** (NEW)
* âœ” **Prevents monolithic implementation files** (NEW)
* âœ” **Ensures granular, manageable tasks** (NEW)
